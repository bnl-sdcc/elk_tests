input {
    beats {
        port => "5044"
    }
}

filter {

    grok {
        pattern_definitions => { "START_TIMESTAMP" => "%{DATE_US} %{TIME}" }
        match => { "message" => [
            '^%{START_TIMESTAMP:starttime} \*\* PID = ',
            '^%{START_TIMESTAMP} Submitting machine is "%{HOSTNAME:submithost}"',
            '^%{START_TIMESTAMP} Starting a VANILLA universe job with ID: %{NUMBER:jobid}',
            '^%{START_TIMESTAMP} Running job as user %{WORD:user}',
            '^%{START_TIMESTAMP:endtime} Notifying exit status=%{NUMBER:status} reason=%{NUMBER:reason}'
        ] }
    }

    ruby { code => '

        # log file name
        # we will use it as key in several dictionaries
        # to identify which line comes from each file and prevent mixing them
        $source = event.get("source")
        
        # Before anything else, we create the dictionaries (empty)
        # to host all relevant variables
        if ! defined?($starttime)
            $starttime = Hash.new
            $starttimebackup = Hash.new
            $jobid = Hash.new
            $submithost = Hash.new
            $user = Hash.new
            $hasuser = Hash.new
            $hasstatus = Hash.new
        end

        if event.get("starttime")

            $starttime[$source] = event.get("starttime")

            if defined?($hasuser[$source]) && $hasstatus[$source] == false
                # if we are here is because all of this is true:
                #   -- we are in the line for a new job, so we are done processing previous one
                #   -- there was an username associated to the previous job
                #   -- there was no final job status associated to the previous job
                # all of that means that the previous job crashed
                event.set("starttime", $starttimebackup[$source])
                event.set("jobid", $jobid[$source])
                event.set("submithost", $submithost[$source])
                event.set("user", $user[$source])
                event.set("status", "CRASHED")
                # we sent the event data to the output
            else
                event.cancel
            end
            
            $starttimebackup[$source] = $starttime[$source]


        elsif event.get("submithost")
            $submithost[$source] = event.get("submithost")
            event.cancel

        elsif event.get("jobid")
            $jobid[$source] = event.get("jobid")
            event.cancel

        elsif event.get("user")
            $user[$source] = event.get("user")
            event.set("starttime", $starttime[$source])
            event.set("jobid", $jobid[$source])
            event.set("submithost", $submithost[$source])
            event.set("user", $user[$source])
            # we sent the event data to the output

            $hasuser[$source] = true
            $hasstatus[$source] = false


        elsif event.get("status")
            event.set("starttime", $starttime[$source])
            event.set("jobid", $jobid[$source])
            event.set("submithost", $submithost[$source])
            event.set("user", $user[$source])
            # we sent the event data to the output

            $hasstatus[$source] = true

        else
            event.cancel
        end

    '}


    mutate { add_field => { "executionhost" => "%{host[name]}" } }

    prune {
        whitelist_names => ["jobid", "user", "submithost", "starttime", "endtime", "status", "reason", "executionhost"]
    }

}



#output {
#    stdout { codec => rubydebug }
#}

output {
    lumberjack {
        codec => json
        hosts => "monitor04.sdcc.bnl.local"
        ssl_certificate => "/etc/logstash/certs/lumberjack.cert"
        ###port => 5005
        port => 5555
    }
}
