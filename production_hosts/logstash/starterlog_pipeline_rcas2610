input {
    beats {
        port => "5044"
    }
}

filter {

    grok {
        pattern_definitions => { "START_TIMESTAMP" => "%{DATE_US} %{TIME}" }
        match => { "message" => [
            '^%{START_TIMESTAMP:starttime} \*\* PID = ',
            '^%{START_TIMESTAMP} Submitting machine is "%{HOSTNAME:submithost}"',
            '^%{START_TIMESTAMP} Starting a VANILLA universe job with ID: %{NUMBER:jobid}',
            '^%{START_TIMESTAMP} Running job as user %{WORD:user}',
            '^%{START_TIMESTAMP:endtime} Notifying exit status=%{NUMBER:status} reason=%{NUMBER:reason}'
        ] }
    }
    grok {
        pattern_definitions => { "START_TIMESTAMP" => "%{DATE_US} %{TIME}" }
        match => { "message" => [
            '^%{START_TIMESTAMP:eventtimestamp}'
        ] }
    }


    date {
        # convert the content of field "eventtimestamp" into a Timestamp object
        # eventtimestamp looks like "03/29/19 15:08:08.841"
        match => ["eventtimestamp", "MM/dd/yy HH:mm:ss.SSS"]
        target => "eventtimestamp"
    }

    ruby { 

        init => '
            # Before anything else, we create the dictionaries (empty)
            # to host all relevant variables
            $starttime = Hash.new
            $starttimebackup = Hash.new
            $jobid = Hash.new
            $submithost = Hash.new
            $user = Hash.new
            $hasuser = Hash.new
            $hasstatus = Hash.new

            # we need to discard too old events, 
            # to avoid dumping too much data into into ElasticSearch
            # initial value for a flag
            $recentenough = Hash.new
        '

        code => '

            # log file name
            # we will use it as key in several dictionaries
            # to identify which line comes from each file and prevent mixing them
            $source = event.get("source")

            # check if we can start processing events
            # or they are still too old
            # we check if the starting line for a new job 
            # is younger than 10 days 
            # we focus on that line in particular to avoid
            # starting the processing in the middle of a running job
            if (! $recentenough[$source]) && event.get("starttime")
                if (Time.now.to_i - event.get("eventtimestamp").to_i) < 864000
                    $recentenough[$source] = true
                end
            end

            if ! $recentenough[$source]
                event.cancel
            elsif

                if event.get("starttime")

                    $starttime[$source] = event.get("starttime")

                    if defined?($hasuser[$source]) && $hasstatus[$source] == false
                        # if we are here is because all of this is true:
                        #   -- we are in the line for a new job, so we are done processing previous one
                        #   -- there was an username associated to the previous job
                        #   -- there was no final job status associated to the previous job
                        # all of that means that the previous job crashed
                        event.set("starttime", $starttimebackup[$source])
                        event.set("jobid", $jobid[$source])
                        event.set("submithost", $submithost[$source])
                        event.set("user", $user[$source])
                        event.set("status", "CRASHED")
                        # we sent the event data to the output
                    else
                        event.cancel
                    end
                    
                    $starttimebackup[$source] = $starttime[$source]


                elsif event.get("submithost")
                    $submithost[$source] = event.get("submithost")
                    event.cancel

                elsif event.get("jobid")
                    $jobid[$source] = event.get("jobid")
                    event.cancel

                elsif event.get("user")
                    $user[$source] = event.get("user")
                    event.set("starttime", $starttime[$source])
                    event.set("jobid", $jobid[$source])
                    event.set("submithost", $submithost[$source])
                    event.set("user", $user[$source])
                    # we sent the event data to the output

                    $hasuser[$source] = true
                    $hasstatus[$source] = false


                elsif event.get("status")
                    event.set("starttime", $starttime[$source])
                    event.set("jobid", $jobid[$source])
                    event.set("submithost", $submithost[$source])
                    event.set("user", $user[$source])
                    # we sent the event data to the output

                    $hasstatus[$source] = true

                else
                    event.cancel
                end

            end            
        '
    }


    mutate { add_field => { "executionhost" => "%{[host][name]}" } }

    mutate {
        split => ["source", "/"]
        add_field => { "logfile" => "%{[source][-1]}"  }
    }


    prune {
        whitelist_names => ["jobid", "user", "submithost", "starttime", "endtime", "status", "reason", "executionhost", "logfile"]
    }

}



#output {
#    stdout { codec => rubydebug }
#}

output {
    lumberjack {
        codec => json
        hosts => "monitor04.sdcc.bnl.local"
        ssl_certificate => "/etc/logstash/certs/lumberjack.cert"
        port => 5555
    }
}
