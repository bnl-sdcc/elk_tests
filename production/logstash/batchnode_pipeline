input {
    beats {
        port => "5044"
    }
}

filter {

    # =========================================================================
    #                           StarterLog
    # =========================================================================


    if [fields][log_type] == "starterlog" {

        grok {
            pattern_definitions => { "START_TIMESTAMP" => "%{DATE_US} %{TIME}" }
            match => { "message" => [
                '^%{START_TIMESTAMP:starttime} \*\* PID = ',
                '^%{START_TIMESTAMP} Submitting machine is "%{HOSTNAME:submithost}"',
                '^%{START_TIMESTAMP} Starting a VANILLA universe job with ID: %{NUMBER:jobid}',
                '^%{START_TIMESTAMP} Running job as user %{WORD:user}',
                '^%{START_TIMESTAMP:endtime} Notifying exit status=%{NUMBER:status} reason=%{NUMBER:reason}',
                '^%{START_TIMESTAMP:eventtimestamp}'
            ] }
            # we do not break on match because 
            # we need to keep matching even when the rule 
            #    '^%{START_TIMESTAMP:eventtimestamp}'
            # is true itself 
            break_on_match => false
        }

        date {
            # convert the content of field "eventtimestamp" into a Timestamp object
            # eventtimestamp looks like "03/29/19 15:08:08.841"
            match => ["eventtimestamp", "MM/dd/yy HH:mm:ss.SSS"]
            target => "eventtimestamp"
        }

        ruby { 

            init => '
                # Before anything else, we create the dictionaries (empty)
                # to host all relevant variables
                $starttime = Hash.new
                $starttimebackup = Hash.new
                $jobid = Hash.new
                $submithost = Hash.new
                $user = Hash.new
                $hasuser = Hash.new
                $hasstatus = Hash.new
                $recentenough = Hash.new

                # we need to discard too old events, 
                # to avoid dumping too much data into into ElasticSearch
                $recentenough = Hash.new

                # return codes 
                $codes = Hash.new
                $codes[4] = "JOB_EXCEPTION: The job exited with an exception"
                $codes[44] = "DPRINTF_ERROR: There is a fatal error with dprintf()"
                $codes[100] = "JOB_EXITED: The job exited (not killed)"
                $codes[101] = "JOB_CKPTED: The job was checkpointed"
                $codes[102] = "JOB_KILLED: The job was killed"
                $codes[103] = "JOB_COREDUMPED: The job was killed and a core file produced"
                $codes[105] = "JOB_NO_MEM: Not enough memory to start the shadow"
                $codes[106] = "JOB_SHADOW_USAGE: incorrect arguments to condor_shadow"
                $codes[107] = "JOB_NOT_CKPTED: The job was kicked off without a checkpoint. JOB_SHOULD_REQUEUE: The effect of this exit code is that we want the job to be put back in the job queue and run again."
                $codes[108] = "JOB_NOT_STARTED: Cannot connect to startd or request refused"
                $codes[109] = "JOB_BAD_STATUS: Job status != RUNNING on startup"
                $codes[110] = "JOB_EXEC_FAILED: failed for some reason other than ENOMEM"
                $codes[111] = "JOB_NO_CKPT_FILE: There is no checkpoint file (lost)"
                $codes[112] = "JOB_SHOULD_HOLD: job should be put on hold"
                $codes[113] = "JOB_SHOULD_REMOVE: The job should be removed"
            '

            code => '

                # log file name
                # we will use it as key in several dictionaries
                # to identify which line comes from each file and prevent mixing them
                $source = event.get("source")

                # check if we can start processing events
                # or they are still too old
                # we check if the starting line for a new job 
                # is younger than 10 days 
                # we focus on that line in particular to avoid
                # starting the processing in the middle of a running job

                if (! $recentenough[$source] ) && event.get("starttime")

                    if (Time.now.to_i - event.get("eventtimestamp").to_i) < 864000
                        $recentenough[$source] = true
                    end
                end

                if ! $recentenough[$source]
                    event.cancel
                elsif

                    if event.get("starttime")

                        $starttime[$source] = event.get("starttime")

                        if defined?($hasuser[$source]) && $hasstatus[$source] == false
                            # if we are here is because all of this is true:
                            #   -- we are in the line for a new job, so we are done processing previous one
                            #   -- there was an username associated to the previous job
                            #   -- there was no final job status associated to the previous job
                            # all of that means that the previous job crashed
                            event.set("starttime", $starttimebackup[$source])
                            event.set("jobid", $jobid[$source])
                            event.set("submithost", $submithost[$source])
                            event.set("user", $user[$source])
                            event.set("status", "CRASHED")
                            # we sent the event data to the output
                        else
                            event.cancel
                        end
                        
                        $starttimebackup[$source] = $starttime[$source]


                    elsif event.get("submithost")
                        $submithost[$source] = event.get("submithost")
                        event.cancel

                    elsif event.get("jobid")
                        $jobid[$source] = event.get("jobid")
                        event.cancel

                    elsif event.get("user")
                        $user[$source] = event.get("user")
                        event.set("starttime", $starttime[$source])
                        event.set("jobid", $jobid[$source])
                        event.set("submithost", $submithost[$source])
                        event.set("user", $user[$source])
                        # we sent the event data to the output

                        $hasuser[$source] = true
                        $hasstatus[$source] = false


                    elsif event.get("status")
                        event.set("starttime", $starttime[$source])
                        event.set("jobid", $jobid[$source])
                        event.set("submithost", $submithost[$source])
                        event.set("user", $user[$source])

                        # add message
                        msg = $codes[event.get("reason").to_i]
                        event.set("explanation", msg)

                        # we sent the event data to the output

                        $hasstatus[$source] = true

                    else
                        event.cancel
                    end

                end            
            '
        }


        mutate { add_field => { "executionhost" => "%{[host][name]}" } }

        mutate {
            split => ["source", "/"]
            add_field => { "logfile" => "%{[source][-1]}"  } 
        }

        prune {
            whitelist_names => ["jobid", "user", "submithost", "starttime", "endtime", "status", "reason", "executionhost", "logfile", "explanation"]
        }


    # =========================================================================
    #                           startd_history 
    # =========================================================================

    } else if [fields][log_type] == "history" {

        grok {
            pattern_definitions => { "END_OF_JOB" => "\*\*\* Offset" }
            match => { "message" => [
                '^GlobalJobId = "%{GREEDYDATA:globaljobid}"',
                '^RemoteUserCpu = %{NUMBER:cpu}',
                '^EnteredCurrentStatus = %{NUMBER:currentstatus_timestamp}',
                '^JobStartDate = %{NUMBER:jobstarttime}',
                '^%{END_OF_JOB:endofjob}'
            ] }
        }

        ruby { 
            code => '
                if event.get("jobstarttime")
                    $starttime = Time.at(event.get("jobstarttime").to_i).strftime("%Y/%m/%d %H:%M:%S") 
                    event.cancel
                elsif event.get("globaljobid")
                    $globaljobid = event.get("globaljobid")
                    event.cancel
                elsif event.get("cpu")
                    $cpu = event.get("cpu")
                    event.cancel
                elsif event.get("currentstatus_timestamp")
                    $currentstatus_timestamp = event.get("currentstatus_timestamp")
                    event.cancel
                elsif event.get("endofjob")
                if (Time.now.to_i - $currentstatus_timestamp.to_i) < 864000
                        event.set("globaljobid", $globaljobid)
                        event.set("cpu", $cpu)
                        event.set("starttime", $starttime)
                    else
                        event.cancel
                    end
                else
                    event.cancel          
                end
            '
        }

        prune {
            whitelist_names => ["globaljobid", "cpu", "starttime"]
        }

    }

}


#output {
#    stdout { codec => rubydebug }
#}

output {
    lumberjack {
        codec => json
        hosts => "************************"
        ssl_certificate => "/etc/logstash/certs/lumberjack.cert"
        port => 5555
    }
}

